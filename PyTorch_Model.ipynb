{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><a href=\"https://www.nvidia.com/en-us/deep-learning-ai/education/\"><img src=\"./assets/DLI_Header.png\"></a></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"structure\"></a>\n",
    "### Create Model Directory Structure\n",
    "\n",
    "\n",
    "```\n",
    "tritonserver --model-repository=/models\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "root@server:/models$ tree\n",
    ".\n",
    "├── simple-onnx-model\n",
    "│   ├── 1\n",
    "│   │   └── model.onnx\n",
    "│   └── config.pbtxt\n",
    "├── simple-pytorch-model\n",
    "│   ├── 1\n",
    "│   │   └── model.pt\n",
    "│   └── config.pbtxt\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p models/simple-pytorch-model\n",
    "!mkdir -p models/simple-pytorch-model/1\n",
    "!mkdir -p models/simple-onnx-model\n",
    "!mkdir -p models/simple-onnx-model/1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>\n",
    "### Define a Simple PyTorch Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.model = models.resnet50(pretrained=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = Model().eval().cuda()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll load the ImageNet labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./imagenet-simple-labels.json') as file:\n",
    "    labels = json.load(file)\n",
    "\n",
    "print(labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "image = Image.open('./assets/goldfish.jpg')\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std = [0.485, 0.456, 0.406]\n",
    "\n",
    "resize = transforms.Resize((256, 256))\n",
    "center_crop = transforms.CenterCrop(224)\n",
    "to_tensor = transforms.ToTensor()\n",
    "normalize = transforms.Normalize(mean=imagenet_mean,\n",
    "                                 std=imagenet_std)\n",
    "\n",
    "transform = transforms.Compose([resize, center_crop, to_tensor, normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensor = transform(image).unsqueeze(0).cuda()\n",
    "logits = model(image_tensor)\n",
    "\n",
    "K = 3\n",
    "values, indices = torch.topk(logits, K)\n",
    "\n",
    "values = values.detach().tolist()[0]\n",
    "indices = indices.detach().tolist()[0]\n",
    "\n",
    "for i in range(K):\n",
    "    print(values[i], indices[i], labels[indices[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTorch_to_TorchScript(nn.Module):\n",
    "    def __init__(self, my_model):\n",
    "        super(PyTorch_to_TorchScript, self).__init__()\n",
    "        self.model = my_model.model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "torchscript_model = PyTorch_to_TorchScript(model).eval().cuda()\n",
    "traced_script_module = torch.jit.script(torchscript_model)\n",
    "traced_script_module.save('models/simple-pytorch-model/1/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, 3, 224, 224).cuda()\n",
    "\n",
    "input_names = ['actual_input_1'] + ['learned_%d' % i for i in range(16)]\n",
    "output_names = ['output1']\n",
    "\n",
    "torch.onnx.export(model, dummy_input, \n",
    "                  'models/simple-onnx-model/1/model.onnx', verbose=False, \n",
    "                  input_names=input_names, output_names=output_names, \n",
    "                  dynamic_axes={'actual_input_1': {0: 'batch_size'}, 'output1': {0: 'batch_size'}})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"configuration\"></a>\n",
    "### Create Configuration File\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = \"\"\"\n",
    "name: \"simple-pytorch-model\"\n",
    "platform: \"pytorch_libtorch\"\n",
    "max_batch_size: 32\n",
    "input [\n",
    " {\n",
    "    name: \"input__0\"\n",
    "    data_type: TYPE_FP32\n",
    "    format: FORMAT_NCHW\n",
    "    dims: [ 3, 224, 224 ]\n",
    "  }\n",
    "]\n",
    "output {\n",
    "    name: \"output__0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 1000 ]\n",
    "  }\n",
    "\"\"\"\n",
    "\n",
    "with open('models/simple-pytorch-model/config.pbtxt', 'w') as file:\n",
    "    file.write(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = \"\"\"\n",
    "name: \"simple-onnx-model\"\n",
    "platform: \"onnxruntime_onnx\"\n",
    "max_batch_size: 32\n",
    "input [\n",
    " {\n",
    "    name: \"actual_input_1\"\n",
    "    data_type: TYPE_FP32\n",
    "    format: FORMAT_NCHW\n",
    "    dims: [ 3, 224, 224 ]\n",
    "  }\n",
    "]\n",
    "output {\n",
    "    name: \"output1\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 1000]\n",
    "  }\n",
    "\"\"\"\n",
    "\n",
    "with open('models/simple-onnx-model/config.pbtxt', 'w') as file:\n",
    "    file.write(configuration)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load\"></a>\n",
    "### Load Model in Triton Inference Server\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sleep 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -v triton:8000/v2/health/ready"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HTTP request returns status 200 if Triton is ready and non-200 if it is not ready.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -v triton:8000/v2/models/simple-pytorch-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -v triton:8000/v2/models/simple-onnx-model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"infer\"></a>\n",
    "### Send Inference Request to Server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonclient.http as tritonhttpclient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERBOSE = False\n",
    "input_name = 'input__0'\n",
    "input_shape = (1, 3, 224, 224)\n",
    "input_dtype = 'FP32'\n",
    "output_name = 'output__0'\n",
    "model_name = 'simple-pytorch-model'\n",
    "url = 'triton:8000'\n",
    "model_version = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triton_client = tritonhttpclient.InferenceServerClient(url=url, verbose=VERBOSE)\n",
    "model_metadata = triton_client.get_model_metadata(model_name=model_name, model_version=model_version)\n",
    "model_config = triton_client.get_model_config(model_name=model_name, model_version=model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_numpy = image_tensor.cpu().numpy()\n",
    "print(image_numpy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input0 = tritonhttpclient.InferInput(input_name, input_shape, input_dtype)\n",
    "input0.set_data_from_numpy(image_numpy, binary_data=False)\n",
    "\n",
    "output = tritonhttpclient.InferRequestedOutput(output_name, binary_data=False)\n",
    "response = triton_client.infer(model_name, model_version=model_version, \n",
    "                               inputs=[input0], outputs=[output])\n",
    "logits = response.as_numpy(output_name)\n",
    "logits = np.asarray(logits, dtype=np.float32)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels[np.argmax(logits)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><a href=\"https://www.nvidia.com/en-us/deep-learning-ai/education/\"><img src=\"./assets/DLI_Header.png\"></a></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
